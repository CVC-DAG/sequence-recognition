{
    "exp_name": "baro_dag001",
    "description": "Attempt at training a model for longer",
    "cipher": "copiale",
    "wandb_mode": "online",
    "wandb_project": "seq-alignment",
    "dirs": {
        "results_dir": "/data2fast/users/ptorras/decrypt/results",
        "base_data_dir": "/data2fast/users/ptorras/copiale",
        "training_file": "gt_words_training.json",
        "training_root": "words",
        "validation_file": "gt_lines_validation.json",
        "validation_root": "lines",
        "test_file": "gt_lines_test.json",
        "test_root": "lines",
        "vocab_data": "vocab.json"
    },
    "data": {
        "target_shape": [512, 64],
        "target_seqlen": 72,
        "aug_pipeline": "basic_decrypt"
    },
    "model": {
        "model_name": "baro_crnn",
        "lstm_hidden_size": 128,
        "lstm_layers": 4,
        "blstm": true,
        "dropout": 0.4,
        "output_classes": 130
    },
    "train": {
        "batch_size": 128,
        "device": "cuda",
        "grad_clip": null,
        "max_epochs": 200,
        "learning_rate": 3e-4,
        "optimizer": "adamw",
        "save_every": 1,
        "eval_every": 1,
        "weight_decay": 1e-5,
        "workers": 8,

        "plateau_sched": true,
        "plateau_factor": 1e-1,
        "plateau_iters": 5,
        "plateau_thresh": 0.01,
        "plateau_min": 1e-7,

        "warmup_sched": false,
        "warmup_factor": 1e-1,
        "warmup_iters": 5000,

        "cosann_sched": false,
        "cosann_t0": 3e-4,
        "cosann_factor": 1e-1,
        "cosann_min": 1e-5
    },
    "beam_width": 30
}